{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The work will be evaluated regarding the ability to explore a solution in detail, assess its quality, and\n",
    "produce critical thinking about it.\n",
    "- We will pay attention to the quality of the code, as well as the clarity of the report and your ability to present\n",
    "results.\n",
    "- Please provide clear instruction for easy installation and testing of your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please communicate the number of hours spent on this test in the report."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time spent on code and report\n",
    "About 35h\n",
    "\n",
    "### Hardware used\n",
    "\n",
    "Everything was done on my Linux PopOS 20.04 laptop with a quadro T2000 GPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Computer Vision Approach\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run instructions:\n",
    "\n",
    "Please checkout the README in AutoGrabCut_Cpp folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach :\n",
    "\n",
    "#### Idea & Assumptions :\n",
    "\n",
    "- Sky region are low entropy areas (no much edge)  \n",
    "- Sky in located in the top 33% percent of the image\n",
    "- There is a strong separation between the sky and the rest of the image : there is an edge\n",
    "\n",
    "The approach is based on the GrabCut algorithm from OpenCV :\n",
    "[\"GrabCut\": interactive foreground extraction using iterated graph cuts](https://dl.acm.org/doi/10.1145/1015706.1015720)\n",
    "\n",
    "It is usually used in an interactive manner (the user select the ROI). Here the area of interest in statically define as the top 33% of the image. \n",
    "\n",
    "GrabCut from OpenCV uses 4 labels, here the top 33% of the image is labelled as \"probable foreground\" and the rest of the image as \"probable background\". \n",
    "\n",
    "A graph minCut then occurs to optimize a split between foreground / background, hopefully sky and the rest of the image\n",
    "\n",
    "#### Edges are not Sky :\n",
    "* In order to help the grabCut algorithm, edges are detected and removed from the initialization. The initialization mask become \"the top 33% of the image, but not where there is an edge\"\n",
    "\n",
    "* This assumption is also exploited as a final stage, to remove from the final binary mask every strong edges of the images. \n",
    "\n",
    "* -> This assumption seems decent enough to be also exploited on deep learning mask, as a post processing step\n",
    "\n",
    "#### Make it faster :\n",
    "* GrabCut is slow. To speedup the process, the image is resized in two stages pyramid. The grabCut is run first on the smaller resolution to get a first mask approximated. This first result then feed a second GrabCut stage to obtain the final mask.\n",
    "\n",
    "* In between steps, the intermediary mask is processed with the same \"edge trick\" and eroded as used as \"annotation\" to the second GrabCut pass.\n",
    "\n",
    "#### Final stage :\n",
    "\n",
    "* the output mask from the last GrabCut is resize to the full scale image resolution. The final mask is processed with morphological operations and blur for de-noising and smoothing.  \n",
    "\n",
    "* Once again the edges from image are exploited to exclude those area from the sky mask.\n",
    "\n",
    "### Subjective Performances and Obvious limitation :\n",
    "\n",
    "* This is fast enough to process video of moderate resolution (720p) at near real time\n",
    "\n",
    "* It work great in case of un-occluded sky and strong sky / land delimitation.\n",
    "\n",
    "* However, it struggle when the conditions deviate too much from the assumptions. \n",
    "\n",
    "* GrabCut algorithm has some internal random initialization and may give unstable result on static image, from run to run\n",
    "\n",
    "* The 33% sky in image is a too strong assumptions, and must be manually adjusted in various cases. \n",
    "\n",
    "* Vegetation branches is hard (you see the sky through branch). Thin structures, such as poles and wires, are hard \n",
    "\n",
    "* Are cloud in the sky (class) ? \n",
    "\n",
    "### Objective Performance :\n",
    "\n",
    "This remains to be done on coco dataset \n",
    "\n",
    "### Things I tried and did not work :\n",
    "\n",
    "* Histogram back-projection :\n",
    "The idea was to get the color statistic of the segmented sky to further refine the mask. On video, it is unstable, and the mask tends to flash.\n",
    "\n",
    "When it works, it performs great around contrasted objet, such as tree branch. It basically perform a color based segmentation. The idea was to only trust it on mask edge, in order to refine them.    \n",
    "\n",
    "### Things I did not tried, but wish I did :\n",
    "\n",
    "* Machine learning color segmentation (KNN, regression, ...) to categorize pixel based on color value. \n",
    "* Machine learning pixel segmentation based on feature+color. (colors + texture)\n",
    "* block based features classification\n",
    "* Connected component post processing / filtering (remove region based on size...)\n",
    "* Some kind of region growing (floodfill, watershed) from color priors (like photoshop magic wand)\n",
    "* explore colorspace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Approach\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "**00_Dataset** contains scripts and notebook to generate binary mask images from Coco and ADE20K dataset\n",
    "\n",
    "both dataset mask are exported in a single folder (one per dataset) along with link to rgb images "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO\n",
    "A pure python script read the annotation, get the proper labels for a given image, and save the mask accordingly\n",
    "\n",
    "### ADE20K\n",
    "A bit simpler than coco, as RGB color value in annotation images encode the class. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Run instructions\n",
    "Setup conda : \n",
    "```\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "in case it doesn't work, checkout full environmentWithVersion.yml \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Project description\n",
    "\n",
    "unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Further"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \n",
    "\n",
    "- save the test image list (save the path)\n",
    "- move confusion matrix code to lib\n",
    "- build an evaluator from image + gtMask + prediction folder\n",
    "- update the cpp to save a binary mask\n",
    "- evaluate the cpp solution on the same test images\n",
    "\n",
    "- train and evaluate on ADE20K"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:05:54) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb3489bcfaf42b8a23b9857c4df484fc8b5c36759b20320d48de64904dcaeb71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
