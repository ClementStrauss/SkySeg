[
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "",
    "section": "",
    "text": "This Repport is better viewed as a notebook\n\n\nAbout 35h\n\n\n\n\nEverything was done on my Linux PopOS 20.04 laptop with a quadro T2000 GPU"
  },
  {
    "objectID": "report.html#traditional-computer-vision-approach",
    "href": "report.html#traditional-computer-vision-approach",
    "title": "",
    "section": "# Traditional Computer Vision Approach",
    "text": "# Traditional Computer Vision Approach"
  },
  {
    "objectID": "report.html#result-folder",
    "href": "report.html#result-folder",
    "title": "",
    "section": "Result folder :",
    "text": "Result folder :\n\n#!pip install ipyplot\nimport ipyplot\n\nfrom glob import glob\nlistofImageNames = glob('02_AutoGrabCut_Cpp/TestImagesCppResults/*.jpg', recursive=True)\n\nipyplot.plot_images(listofImageNames, img_width=200)\n\n\n    \n    \n        \n        show html\n                    \n        <style>\n        #ipyplot-imgs-container-div-UtgTjm4tt3KBW4k37qcXvs {\n            width: 100%;\n            height: 100%;\n            margin: 0%;\n            overflow: auto;\n            position: relative;\n            overflow-y: scroll;\n        }\n\n        div.ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs {\n            width: 200px;\n            display: inline-block;\n            margin: 3px;\n            position: relative;\n        }\n\n        div.ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs {\n            width: 200px;\n            background: white;\n            display: inline-block;\n            vertical-align: top;\n            text-align: center;\n            position: relative;\n            border: 2px solid #ddd;\n            top: 0;\n            left: 0;\n        }\n\n        div.ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs span.ipyplot-img-close {\n            display: none;\n        }\n\n        div.ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs span {\n            width: 100%;\n            height: 100%;\n            position: absolute;\n            top: 0;\n            left: 0;\n        }\n\n        div.ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs img {\n            width: 200px;\n        }\n\n        div.ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs span.ipyplot-img-close:hover {\n            cursor: zoom-out;\n        }\n        div.ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs span.ipyplot-img-expand:hover {\n            cursor: zoom-in;\n        }\n\n        div[id^=ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs]:target {\n            transform: scale(2.5);\n            transform-origin: left top;\n            z-index: 5000;\n            top: 0;\n            left: 0;\n            position: absolute;\n        }\n\n        div[id^=ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs]:target span.ipyplot-img-close {\n            display: block;\n        }\n\n        div[id^=ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs]:target span.ipyplot-img-expand {\n            display: none;\n        }\n        </style>\n    <div id=\"ipyplot-imgs-container-div-UtgTjm4tt3KBW4k37qcXvs\">\n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-4m8nphEgerVvKgDk7fCVqE\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">0</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/exemple1.png.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/exemple1.png.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-4m8nphEgerVvKgDk7fCVqE\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-5MqBRVLMUsCtfveqvFY3Yu\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">1</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/On-the-Road.png.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/On-the-Road.png.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-5MqBRVLMUsCtfveqvFY3Yu\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-iBDDJfxy92dbNztfmsvsyW\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">2</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/patrick-tomasso-SVVTZtTGyaU-unsplash.jpg.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/patrick-tomasso-SVVTZtTGyaU-unsplash.jpg.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-iBDDJfxy92dbNztfmsvsyW\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-MUxfZKvAZWsqXoFgP84Ybv\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">3</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/2._MAD_12003_Chaoyang_Park_Plaza_i_02_overview_with_city_context.jpg.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/2._MAD_12003_Chaoyang_Park_Plaza_i_02_overview_with_city_context.jpg.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-MUxfZKvAZWsqXoFgP84Ybv\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-S7cfgxZcZ5huhRPvBJpH9i\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">4</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/750x422.jpeg.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/750x422.jpeg.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-S7cfgxZcZ5huhRPvBJpH9i\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-efV3cm63TZL2y6zgp2fc4B\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">5</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/635x487_100_300_000000x10x0.png.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/635x487_100_300_000000x10x0.png.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-efV3cm63TZL2y6zgp2fc4B\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-drm4Fs4G8xX7zPhCdKSzmD\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">6</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/ryan-schroeder-Gg7uKdHFb_c-unsplash.jpg.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/ryan-schroeder-Gg7uKdHFb_c-unsplash.jpg.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-drm4Fs4G8xX7zPhCdKSzmD\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-L4JDeS9dKXHFpkF2HFs5oA\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">7</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/ml_elcamino_ontheroad_02_0.jpg.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/ml_elcamino_ontheroad_02_0.jpg.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-L4JDeS9dKXHFpkF2HFs5oA\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-bru8fzB5VZetgWgFbhUKa5\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">8</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/photo-1625726411847-8cbb60cc71e6.jpeg.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/photo-1625726411847-8cbb60cc71e6.jpeg.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-bru8fzB5VZetgWgFbhUKa5\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-8oPiZX24YGUP93UXKrs5pU\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">9</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/route-deserte-montagnes-arriere-plan-dans-paysage-aride-iles-canaries-fuerteventura_462054-226.jpg.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/route-deserte-montagnes-arriere-plan-dans-paysage-aride-iles-canaries-fuerteventura_462054-226.jpg.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-8oPiZX24YGUP93UXKrs5pU\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-guPDWUAuEDfSroHG2UK2y4\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">10</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/photo1.jpeg.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/photo1.jpeg.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-guPDWUAuEDfSroHG2UK2y4\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-BViyhMgsWdoNTPafPxzKZK\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">11</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/shanghai-morning-city-landscape-empty-asphalt-road-shanghai-morning-city-landscape-asphalt-road-155904083.jpg.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/shanghai-morning-city-landscape-empty-asphalt-road-shanghai-morning-city-landscape-asphalt-road-155904083.jpg.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-BViyhMgsWdoNTPafPxzKZK\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    \n    <div class=\"ipyplot-placeholder-div-UtgTjm4tt3KBW4k37qcXvs\">\n        <div id=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-8LhhpSSe6aiTx7VeJ5NjHA\" class=\"ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs\">\n            <h4 style=\"font-size: 12px; word-wrap: break-word;\">12</h4>\n            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">02_AutoGrabCut_Cpp/TestImagesCppResults/12.jpg.CppComposite.jpg</h4><img src=\"02_AutoGrabCut_Cpp/TestImagesCppResults/12.jpg.CppComposite.jpg\"/>\n            <a href=\"#!\">\n                <span class=\"ipyplot-img-close\"/>\n            </a>\n            <a href=\"#ipyplot-content-div-UtgTjm4tt3KBW4k37qcXvs-8LhhpSSe6aiTx7VeJ5NjHA\">\n                <span class=\"ipyplot-img-expand\"/>\n            </a>\n        </div>\n    </div>\n    </div>\n        \n    \n    \n\n\n\n        \n    \n    \n        \n            0\n            02_AutoGrabCut_Cpp/TestImagesCppResults/exemple1.png.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            1\n            02_AutoGrabCut_Cpp/TestImagesCppResults/On-the-Road.png.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            2\n            02_AutoGrabCut_Cpp/TestImagesCppResults/patrick-tomasso-SVVTZtTGyaU-unsplash.jpg.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            3\n            02_AutoGrabCut_Cpp/TestImagesCppResults/2._MAD_12003_Chaoyang_Park_Plaza_i_02_overview_with_city_context.jpg.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            4\n            02_AutoGrabCut_Cpp/TestImagesCppResults/750x422.jpeg.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            5\n            02_AutoGrabCut_Cpp/TestImagesCppResults/635x487_100_300_000000x10x0.png.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            6\n            02_AutoGrabCut_Cpp/TestImagesCppResults/ryan-schroeder-Gg7uKdHFb_c-unsplash.jpg.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            7\n            02_AutoGrabCut_Cpp/TestImagesCppResults/ml_elcamino_ontheroad_02_0.jpg.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            8\n            02_AutoGrabCut_Cpp/TestImagesCppResults/photo-1625726411847-8cbb60cc71e6.jpeg.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            9\n            02_AutoGrabCut_Cpp/TestImagesCppResults/route-deserte-montagnes-arriere-plan-dans-paysage-aride-iles-canaries-fuerteventura_462054-226.jpg.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            10\n            02_AutoGrabCut_Cpp/TestImagesCppResults/photo1.jpeg.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            11\n            02_AutoGrabCut_Cpp/TestImagesCppResults/shanghai-morning-city-landscape-empty-asphalt-road-shanghai-morning-city-landscape-asphalt-road-155904083.jpg.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n    \n        \n            12\n            02_AutoGrabCut_Cpp/TestImagesCppResults/12.jpg.CppComposite.jpg\n            \n                \n            \n            \n                \n            \n        \n    \n    \n\n\n\nBuild and Run instructions:\nPlease checkout the README in AutoGrabCut_Cpp folder 02_AutoGrabCut_Cpp\n\n\nApproach :\n\nIdea & Assumptions :\n\nSky region are low entropy areas (no much edge)\n\nSky in located in the top 33% percent of the image\nThere is a strong separation between the sky and the rest of the image : there is an edge\n\nThe approach is based on the GrabCut algorithm from OpenCV : “GrabCut”: interactive foreground extraction using iterated graph cuts\nIt is usually used in an interactive manner (the user select the ROI). Here the area of interest in statically define as the top 33% of the image.\nGrabCut from OpenCV uses 4 labels, here the top 33% of the image is labelled as “probable foreground” and the rest of the image as “probable background”.\nA graph minCut then occurs to optimize a split between foreground / background, hopefully sky and the rest of the image\n\n\nEdges are not Sky :\n\nIn order to help the grabCut algorithm, edges are detected and removed from the initialization. The initialization mask become “the top 33% of the image, but not where there is an edge”\nThis assumption is also exploited as a final stage, to remove from the final binary mask every strong edges of the images.\n-> This assumption seems decent enough to be also exploited on deep learning mask, as a post processing step\n\n\n\nMake it faster :\n\nGrabCut is slow. To speedup the process, the image is resized in two stages pyramid. The grabCut is run first on the smaller resolution to get a first mask approximated. This first result then feed a second GrabCut stage to obtain the final mask.\nIn between steps, the intermediary mask is processed with the same “edge trick” and eroded as used as “annotation” to the second GrabCut pass.\n\n\n\nFinal stage :\n\nthe output mask from the last GrabCut is resize to the full scale image resolution. The final mask is processed with morphological operations and blur for de-noising and smoothing.\nOnce again the edges from image are exploited to exclude those area from the sky mask.\n\n\n\n\nSubjective Performances and Obvious limitation :\n\nThis is fast enough to process video of moderate resolution (720p) at near real time\nIt work great in case of un-occluded sky and strong sky / land delimitation.\nHowever, it struggle when the conditions deviate too much from the assumptions.\nGrabCut algorithm has some internal random initialization and may give unstable result on static image, from run to run\nThe 33% sky in image is a too strong assumptions, and must be manually adjusted in various cases.\nVegetation branches is hard (you see the sky through branch). Thin structures, such as poles and wires, are hard\nAre cloud in the sky (class) ?\n\n\n\nObjective Performance :\nThis remains to be done on annotated dataset. However, the repository contains a script to process the whole COCO dataset (or ADE20K) and save binary image masks.\n\n\nThings I tried and did not work :\n\nHistogram back-projection : The idea was to get the color statistic of the segmented sky to further refine the mask. On video, it is unstable, and the mask tends to flash.\n\nWhen it works, it performs great around contrasted objet, such as tree branch. It basically perform a color based segmentation. The idea was to only trust it on mask edge, in order to refine them.\n\n\nThings I did not tried, but wish I did :\n\nMachine learning color segmentation (KNN, regression, …) to categorize pixel based on color value.\nMachine learning pixel segmentation based on feature+color. (colors + texture)\nblock based features classification\nConnected component post processing / filtering (remove region based on size…)\nSome kind of region growing (floodfill, watershed) from color priors (like photoshop magic wand)\nexplore colorspace"
  },
  {
    "objectID": "report.html#dataset-preparation",
    "href": "report.html#dataset-preparation",
    "title": "",
    "section": "Dataset Preparation",
    "text": "Dataset Preparation\n00_Dataset contains scripts and notebook to generate binary mask images from Coco and ADE20K dataset\nboth dataset mask are exported in a single folder (one per dataset) along with link to rgb images\n\nCOCO\nA pure python script read the annotation, get the proper labels for a given image, and save the mask accordingly\n\n\nADE20K\nA bit simpler than coco, as RGB color value in annotation images encode the class."
  },
  {
    "objectID": "report.html#build-and-run-instructions-1",
    "href": "report.html#build-and-run-instructions-1",
    "title": "",
    "section": "Build and Run instructions",
    "text": "Build and Run instructions\nSetup conda :\nconda env create -f environment.yml\nin case it doesn’t work, checkout full environmentWithVersion.yml"
  },
  {
    "objectID": "report.html#project",
    "href": "report.html#project",
    "title": "",
    "section": "Project",
    "text": "Project\n\nA Unet network is trained on ADE20k dataset\nTraining part and evaluation part are in distinct notebooks, checkout those for more information\nResult are tested on coco (part of it)\n\n./01_DeepLearning/TrainUnet.ipynb\n./01_DeepLearning/EvaluateModel.ipynb\n\nObjective Performance :\nEvaluation is on part of the coco validation dataset (trained on ADE20K)\n\nResNet18 training :\n\n\n\nResNet18\n\n\n\n\nResNet34 training :\n\n\n\nResNet34\n\n\n–> Both network performs about the same here, Resnet34 seems slightly better on Sky\n\n\n\nSubjective Performances :\n\nOn the test images, resnet18 Unet training seems to perform more consistently compared to resnet34. This is unexpected and does not match the objective performance measures.\n\nResnet18:  Resnet34: \n\n\nResults discussion\n\nTrainings converges toward the objectives, as shown by the confusion matrix, and as expected. However, during test on real “big” images, results are a bit inconsistent, or even poor in the ResNet34 case. Additional tests need to be done, but it seems that generalization of the network could be improved.\nI trained the networks with progressive resizing. Great trick to train faster, and fine tune on larger input size.\nThere is something to tune (or experiment) between the scaling of the train images and the scaling done in the augmentation to create the batches. (in relationship with the kind of image expected in the final application)\nThe dataset (ADE20K) seems of quality for the task, and should be ok to process the test images. However image resolution are on the lower side compared to test images.\nI noted some poor annotations showing up when displaying sample with the “worst loss”. Some training images may need to be removed.\nAnnotations on ADE20k seems to be of good quality. However contours are a bit rough, and annotations on hard cases (tree branch, thin structures) may be poor.\n\n\n\nSome thoughts :\n\nThe discrepancy between the Resnet18 and ResNet34 is bothering me. Ideally, I would retrain the ResNet34 in the same exact conditions as ResNet18 to be sure. Check the progressive resizing.\nProcessing the image at different scale (on the mini dataset) give different results : what is the optimal resolution in this case?. Does DeepLab architecture could perform better with multi-scale features?\nThere is no pre processing of the image and no post processing of the mask\n\n\n\nThings I wish I did :\n\nTest an ‘off the shelf’ segmentation network as a benchmark\nTest DeeplabV3 architecture on this problem\nTest the deeplab tflite model present in the GoPro App\nQuantize the model to test it on Android (ONNX, tflite)\nMy GPU has limitations, better rent some remote compute next time."
  }
]